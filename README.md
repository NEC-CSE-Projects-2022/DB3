
ğŸš€DB3 â€“ :Unifying Vision and Language for Robust Fake News Detection Using 
Novel Deep Samples

ğŸ«‚ Team Information
 Shaik Siraz- 22471A05O2 ( [LinkedIn](https://www.linkedin.com/in/siraz-shaik-25108a28b) )
 Contribution:
 - Complete end-to-end project implementation
 - Dataset selection and preparation
 - Image preprocessing and enhancement pipeline
 - MobileNetV2 fine-tuning and optimization
 - Attention mechanism integration
 - Model training, validation, and evaluation
 - Comparative analysis with multiple CNN architectures
 - Result analysis, documentation, and GitHub setup
 ---
Shaik Malka Jan Shafi- 22471A0509 ( [LinkedIn](https://www.linkedin.com/in/jan-shafi-shaik-malka-432664287) )
Work Done: 
- Literature survey assistance
- Dataset understanding and validation support
- Result verification and documentation support
---
Nuti Nanda Kameswar- 23475A0504 ( [LinkedIn](https://www.linkedin.com/in/nanda-kameswar-801784207) )
Work Done: 
- Model testing assistance
- Presentation preparation
- Project report formatting

---

ğŸ“Œ Abstract
â€”Fake news identification has gained itâ€™s relevance
over the last few years as a result of the large-scale propagation
of fake information through social media. The paper presents
a new method for detecting fake news that uses both text and
image information together for identification with multimodal
learning that combines both text and image modalities. Using
the Fakeddit dataset, three new models were created and tested:
(1) Retrained MLP Classifier with BERT + MobileNetV2 (91
precision), (2) CLIP + MLP (88.24 precision) and (3) DistilBERT
+ EfficientNet + MLP (89 precision). The three models all achieve
better performance than the baseline 88.83 in the original paper.
This paper proves that combining different architectures beyond
the conventional literature can achieve better classification results
in fake news.The three models all achieve better performance
than the baseline 88.83% from the original paper.
Index Terms-Fake news detection, multimodal deep learning,
transformer models, BERT, MobileNetV2, CLIP, DistilBERT,
EfficientNet, MLP, vision language fusion, binary classification,
lightweight neural networks, deep fusion architectures.

---

## Paper Reference (Inspiration)
ğŸ‘‰ **[Paper Title Multimodal Fake News Detection Based on Contrastive Learning and Similarity Fusion
  â€“ Author Names Yan Li
 ](https://ieeexplore.ieee.org/document/10718307)**
This project is inspired by the architectural concepts, attention mechanisms, and preprocessing strategies presented in the Yan Li research paper, while adapting the implementation to a MobileNetV2-based lightweight architecture suitable for academic and practical deployment.

---

âœ¨ Our Improvement Over Existing Paper
- Lightweight MobileNetV2 backbone instead of heavier CNNs
- Reduced computational cost while maintaining high accuracy
- Designed for easy deployment and academic reproducibility

---

ğŸ“Œ About the Project
ğŸ” What the Project Does
This project presents a Multimodal Fake News Detection System that automatically classifies news posts as:

âœ… Real News

âŒ Fake News

The system analyzes both:

ğŸ“ Text content (headlines/titles)

ğŸ–¼ Associated images

It uses advanced deep learning architectures to combine visual and textual information for robust classification.
ğŸ”„ System Workflow
Text Input + Image Input
â†“
Text Preprocessing (Cleaning, Tokenization)
â†“
Image Preprocessing (Resizing, Normalization)
â†“
Feature Extraction

BERT / DistilBERT (Text Encoder)

MobileNetV2 / EfficientNet / CLIP (Image Encoder)
â†“
Multimodal Feature Fusion (Concatenation / Unified Embedding)
â†“
MLP Classifier
â†“
Prediction (Real / Fake)

---

 ğŸ“ Dataset Used
Fakeddit Multimodal Dataset

A large-scale multimodal fake news dataset containing Reddit posts with:

Post title (text)

Associated image

Binary label (Real / Fake)

ğŸ“Š Dataset Statistics (After Filtering)
Split	Total Samples	Real	Fake
Train	40,000	20,000	20,000
Validation	5,000	2,500	2,500
Test	5,000	2,500	2,500
Total	50,000	25,000	25,000

---
ğŸ›  Technologies & Dependencies
Python 3.x

TensorFlow / PyTorch

HuggingFace Transformers

OpenAI CLIP

NumPy

Pandas

OpenCV

Matplotlib

Scikit-learn

Google Colab (Tesla T4 GPU)

---

ğŸ” Data Preprocessing
ğŸ“ Text Processing
Lowercasing

Special character removal

Tokenization

Encoding using BERT/DistilBERT tokenizer

ğŸ–¼ Image Processing
Resizing to 224 Ã— 224

Normalization with ImageNet statistics

Removal of corrupted/missing images

ğŸ· Label Encoding
Real â†’ 0

Fake â†’ 1

ğŸ§ª Model Architectures
1ï¸âƒ£ BERT + MobileNetV2 + MLP (Best Performing Model)
Text Encoder: BERT (768-dim embeddings)

Image Encoder: MobileNetV2 (1280-dim features)

Fusion: Feature Concatenation

Classifier: Multi-Layer Perceptron

Loss: Binary Cross-Entropy

Optimizer: AdamW

2ï¸âƒ£ CLIP + MLP
Unified 512-dim multimodal embeddings

Direct multimodal alignment

Lightweight architecture

3ï¸âƒ£ DistilBERT + EfficientNet + MLP
Reduced computational complexity

Suitable for edge deployment

Dropout + ReLU activation

âš™ Training Configuration
Parameter	Value
Batch Size	32
Epochs	10â€“15
Optimizer	AdamW
Learning Rate	2e-5 (BERT), 1e-4 (Others)
Loss Function	Binary Cross-Entropy
Platform	Google Colab (GPU)
ğŸ“Š Model Evaluation
ğŸ“ˆ Metrics Used
Accuracy

Precision

Recall

F1-Score

Confusion Matrix
---

ğŸ† Performance Results
ğŸ”¹ Model Comparison
Model	Accuracy	F1-Score
BERT + MobileNetV2 + MLP	91.03%	0.91
CLIP + MLP	88.23%	0.88
DistilBERT + EfficientNet + MLP	82.00%	0.82
Base Paper (Bagged CNN)	88.83%	0.88
âœ… Proposed model outperforms base paper benchmark (88.83%)
âœ… Strong generalization across both Real and Fake classes
âœ… Efficient multimodal fusion improves accuracy

ğŸ”¬ Ablation Study
Modality	Accuracy
Text-only (BERT)	87.50%
Image-only (MobileNetV2)	82.00%
Multimodal Fusion	91.03%
---
ğŸ“Œ Multimodal learning clearly improves classification performance.

âš  Limitations & Future Work
ğŸ”» Limitations
Binary classification only

Late fusion architecture

No explainability module integrated

Tested on single dataset (Fakeddit)
---

ğŸš€ Future Enhancements
Cross-modal attention mechanisms

Explainable AI (Grad-CAM, LIME)

Multilingual fake news detection

Federated learning integration

Real-time social media deployment

3-way or multi-class classification
---

ğŸŒ Deployment Applications
Social media misinformation monitoring

News verification platforms

Browser extensions for fake news alerts

Content moderation tools

AI-based fact-checking systems

ğŸ‘¨â€ğŸ’» Developed By
Shaik Siraz
Project Lead & Developer
ğŸ”— https://www.linkedin.com/in/siraz-shaik-25108a28b


ğŸ“§ Email: sksiraz29@gmail.com
ğŸ”— LinkedIn: (https://www.linkedin.com/in/siraz-shaik-25108a28b)


ğŸ™ Acknowledgments
Fakeddit Dataset Contributors

HuggingFace Transformers Library

OpenAI CLIP Framework

Google Colab GPU Resources

Research Community & IEEE References


---
